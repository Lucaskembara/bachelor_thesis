{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading in the data\n",
    "train_data = pd.read_csv(\"data/data_final/train_data.csv\")\n",
    "test_data = pd.read_csv(\"data/data_final/test_data.csv\")\n",
    "y_train = pd.read_csv(\"data/data_final/train_y.csv\").to_numpy()\n",
    "y_test = pd.read_csv(\"data/data_final/test_y.csv\").to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def create_tfidf(analyzer, char_low, char_high, X_train, X_test):\n",
    "    bow_transform = CountVectorizer(analyzer = analyzer, ngram_range = (char_low, char_high))\n",
    "    X_train_bow = bow_transform.fit_transform(X_train)\n",
    "    X_test_bow = bow_transform.transform(X_test)\n",
    "    tfidf_trfm = TfidfTransformer(norm=None)\n",
    "    X_train_tfidf = tfidf_trfm.fit_transform(X_train_bow)\n",
    "    X_test_tfidf = tfidf_trfm.transform(X_test_bow)\n",
    "    \n",
    "    return [analyzer, char_low, char_high, X_train_bow, X_test_bow, X_train_tfidf, X_test_tfidf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer_types = [\"word\", \"char\", \"char_wb\"]\n",
    "ngram_ranges = [1, 2, 3, 4, 5]\n",
    "\n",
    "features_list = []\n",
    "\n",
    "for analyzer in analyzer_types:\n",
    "    for ngram in ngram_ranges:\n",
    "        features = create_tfidf(analyzer, ngram, ngram, train_data['clean_text'], test_data['clean_text'])\n",
    "        features_list.append(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.plot(n_comp, explained)\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel(\"Explained Variance\")\n",
    "plt.title(\"Plot of Number of components v/s explained variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "component_list = []\n",
    "\n",
    "for feature_set in features_list:\n",
    "    n_comp = [5,10,15,20,50,100,150,200,500,700,800,900,1000,1500,2000,2500,3000,3500]\n",
    "    explained = []\n",
    "    \n",
    "    for x in n_comp:\n",
    "        if x > feature_set[5].shape[0]:\n",
    "            break\n",
    "        svd = TruncatedSVD(n_components=x)\n",
    "        svd.fit(feature_set[5])\n",
    "        explained.append(svd.explained_variance_ratio_.sum())\n",
    "        if svd.explained_variance_ratio_.sum() > 0.95:\n",
    "            component_list.append([feature_set[0], feature_set[1], feature_set[2], x])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "truncated_features_list = features_list\n",
    "\n",
    "for feature_set in features_list:\n",
    "    print(feature_set)\n",
    "    svd = TruncatedSVD(n_components = component_list[counter][3], n_iter=7, random_state=42)\n",
    "    svd_x = svd.fit_transform(feature_set[5])\n",
    "    svd_tr = svd.transform(feature_set[6])\n",
    "    \n",
    "    truncated_features_list[counter][5] = svd_x\n",
    "    truncated_features_list[counter][6] = svd_tr\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "param_list = []\n",
    "\n",
    "for feature_set in truncated_features_list:\n",
    "    rf_base = SVC(random_state = 1)\n",
    "\n",
    "\n",
    "    param_grid = [\n",
    "      {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "      {'C': [1, 10, 100, 1000], 'degree': [1, 2], 'gamma': [0.1, 0.01, 0.001, 0.0001], 'kernel': ['poly']},\n",
    "      {'C': [1, 10, 100, 1000], 'degree': [1, 2, 3, 4, 5], 'gamma': [0.1, 0.01, 0.001, 0.0001], 'kernel': ['rbf']},\n",
    "      {'C': [1, 10, 100, 1000], 'gamma': [0.1, 0.01, 0.001, 0.0001], 'kernel': ['sigmoid']}\n",
    "     ]\n",
    "\n",
    "    rf_random = GridSearchCV(\n",
    "        SVC(), param_grid, scoring='f1', cv = 3, verbose = 10, n_jobs = -1\n",
    "        )\n",
    "\n",
    "    rf_random.fit(feature_set[5], train_data['Label'])\n",
    "\n",
    "    param_list.append([feature_set[0], feature_set[1], feature_set[2], rf_random.best_params_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "count = 0\n",
    "\n",
    "result_list = param_list\n",
    "\n",
    "for hyperparameter in param_list:\n",
    "    kernel = hyperparameter[3].get('kernel')\n",
    "    C = hyperparameter[3].get('C')\n",
    "    gamma = hyperparameter[3].get('gamma')\n",
    "    degree = hyperparameter[3].get('degree')\n",
    "    \n",
    "    if kernel == 'linear':\n",
    "        test_model = SVC(kernel = 'linear', C = C)\n",
    "    elif kernel == 'sigmoid':\n",
    "        test_model = SVC(kernel = 'sigmoid', C = C, gamma = gamma)\n",
    "    elif kernel == 'rbf':\n",
    "        test_model = SVC(kernel = 'rbf', C = C, gamma = gamma, degree = degree)\n",
    "    \n",
    "    test_model.fit(truncated_features_list[count][5], y_train.ravel())\n",
    "    y_true, y_pred = y_test.ravel(), test_model.predict(truncated_features_list[count][6])\n",
    "    \n",
    "    result_list[count].append(f1_score(y_true, y_pred))\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_train = pd.read_csv(\"data/data_final/train_hc.csv\")\n",
    "hc_test = pd.read_csv(\"data/data_final/test_hc.csv\")\n",
    "liwc_train = pd.read_csv(\"data/data_final/train_data_liwc.csv\")\n",
    "liwc_test = pd.read_csv(\"data/data_final/test_data_liwc.csv\")\n",
    "\n",
    "train_df = pd.DataFrame(data = truncated_features_list[9][5])\n",
    "test_df = pd.DataFrame(data = truncated_features_list[9][6])\n",
    "\n",
    "comb_train_all = pd.concat([train_df, hc_train, liwc_train], axis = 1)\n",
    "comb_test_all = pd.concat([test_df, hc_test, liwc_test], axis = 1)\n",
    "\n",
    "comb_train_hc = pd.concat([train_df, hc_train], axis = 1)\n",
    "comb_test_hc = pd.concat([test_df, hc_train], axis = 1)\n",
    "\n",
    "comb_train_liwc = pd.concat([train_df, liwc_train], axis = 1)\n",
    "comb_test_liwc = pd.concat([test_df, liwc_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "test_model = SVC(kernel = 'sigmoid', C = 100, gamma = 0.001)\n",
    "test_model.fit(truncated_features_list[9][5], y_train.ravel())\n",
    "y_true, y_pred = y_test.ravel(), test_model.predict(truncated_features_list[9][6])\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools   \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "\n",
    "plt.imshow(cf,cmap=plt.cm.Blues,interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "tick_marks = np.arange(len(set(y_pred))) # length of classes\n",
    "class_labels = ['0','1']\n",
    "tick_marks\n",
    "plt.xticks(tick_marks,class_labels)\n",
    "plt.yticks(tick_marks,class_labels)\n",
    "# plotting text value inside cells\n",
    "thresh = cf.max() / 2.\n",
    "for i,j in itertools.product(range(cf.shape[0]),range(cf.shape[1])):\n",
    "    plt.text(j,i,format(cf[i,j],'d'),horizontalalignment='center',color='white' if cf[i,j] >thresh else 'black')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_train = pd.read_csv(\"data/data_final/train_hc.csv\")\n",
    "hc_test = pd.read_csv(\"data/data_final/test_hc.csv\")\n",
    "liwc_train = pd.read_csv(\"data/data_final/train_data_liwc.csv\")\n",
    "liwc_test = pd.read_csv(\"data/data_final/test_data_liwc.csv\")\n",
    "\n",
    "train_df = pd.DataFrame(data = truncated_features_list[9][5])\n",
    "test_df = pd.DataFrame(data = truncated_features_list[9][6])\n",
    "\n",
    "comb_train_all = pd.concat([train_df, hc_train, liwc_train], axis = 1)\n",
    "comb_test_all = pd.concat([test_df, hc_test, liwc_test], axis = 1)\n",
    "\n",
    "comb_train_hc = pd.concat([train_df, hc_train], axis = 1)\n",
    "comb_test_hc = pd.concat([test_df, hc_train], axis = 1)\n",
    "\n",
    "comb_train_liwc = pd.concat([train_df, liwc_train], axis = 1)\n",
    "comb_test_liwc = pd.concat([test_df, liwc_test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "test_model = SVC(kernel = 'poly', C = 1, gamma = 0.01, degree = 1)\n",
    "test_model.fit(comb_train_all, y_train.ravel())\n",
    "y_true, y_pred = y_test.ravel(), test_model.predict(comb_test_all)\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools   \n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cf = confusion_matrix(y_true, y_pred, labels=None, sample_weight=None, normalize=None)\n",
    "\n",
    "plt.imshow(cf,cmap=plt.cm.Blues,interpolation='nearest')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "tick_marks = np.arange(len(set(y_pred))) # length of classes\n",
    "class_labels = ['0','1']\n",
    "tick_marks\n",
    "plt.xticks(tick_marks,class_labels)\n",
    "plt.yticks(tick_marks,class_labels)\n",
    "# plotting text value inside cells\n",
    "thresh = cf.max() / 2.\n",
    "for i,j in itertools.product(range(cf.shape[0]),range(cf.shape[1])):\n",
    "    plt.text(j,i,format(cf[i,j],'d'),horizontalalignment='center',color='white' if cf[i,j] >thresh else 'black')\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
